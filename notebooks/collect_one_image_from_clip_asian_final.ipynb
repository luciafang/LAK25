{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T06:29:45.105147Z",
     "start_time": "2024-08-17T06:29:41.763462Z"
    }
   },
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "from deepface.modules import modeling, detection, preprocessing"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T06:29:46.702913Z",
     "start_time": "2024-08-17T06:29:46.699106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = os.listdir('../EA_annotated_3Blue1Brown/')\n",
    "print(dataset)"
   ],
   "id": "fef38d7f9ecdd590",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jerick', 'alex', 'xuyelin', '.DS_Store', 'amazon', 'CSA', 'lucia', '202', 'cody', 'qiaoyuewei', 'steffi', 'laura', 'jack', 'ucla', 'xiaoruiwei', 'senfen', 'coda', 'qipao']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T06:29:48.297921Z",
     "start_time": "2024-08-17T06:29:48.294584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_int(s):\n",
    "    if s.isdigit():\n",
    "        return int(s)\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "\n",
    "def alphanum_key(s):\n",
    "    return [convert_int(c) for c in re.split('([0-9]+)', s)]\n",
    "\n",
    "\n",
    "def sort_nicely(l):\n",
    "    l.sort(key=alphanum_key)"
   ],
   "id": "7b6dead576bbc310",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:01:58.703230Z",
     "start_time": "2024-08-17T06:29:49.923435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2 lists  to store the following\n",
    "# list of features (images)\n",
    "#{0: [[3, 1, 2, 2][4, 3, 2, 2]]}\n",
    "# list of labels (confused or not)\n",
    "#{0: 3}\n",
    "\n",
    "features_list = []\n",
    "labels_list = []\n",
    "outfile_name = '../data_features_labels/EA_annotated_3Blue1Brown_final.pkl'\n",
    "# loop over the train and test and validation\n",
    "for name in tqdm(dataset):\n",
    "    # print(ttv, os.path.exists('DataSet/'+ttv+'/'))\n",
    "    \n",
    "    if name != '.DS_Store' and os.path.exists('../EA_annotated_3Blue1Brown/'+name+'/'):\n",
    "        # train, test, validation\n",
    "            \n",
    "        # return all images in this directory\n",
    "        content_list = os.listdir('../EA_annotated_3Blue1Brown/'+name+'/')\n",
    "        # remove video for below\n",
    "        img_list = [c for c in content_list if c.endswith('.jpg')]\n",
    "        sort_nicely(img_list)\n",
    "        \n",
    "        nc_count = 0\n",
    "        c_count = 0        \n",
    "        for j, item in enumerate(img_list):   \n",
    "            img_path = os.path.abspath('.')+'/../EA_annotated_3Blue1Brown/'+name+'/'+item\n",
    "            img = cv2.imread(str(img_path)) \n",
    "            img_objs = detection.extract_faces(\n",
    "                img_path=img,\n",
    "                detector_backend='mtcnn',\n",
    "                grayscale=False,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            # for cv2 to read the image\n",
    "            cv2.imwrite('placeholder.jpg', 255*img_objs[0]['face'])\n",
    "            cropped_img = cv2.imread('placeholder.jpg')\n",
    "            img_gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "            img_gray = cv2.resize(img_gray, (64, 64))\n",
    "            \n",
    "            # img is 3d array (w, h, 1), label is confusion_val\n",
    "            # features_list.append(img_gray)\n",
    "            \n",
    "            if 'not confused' in item:\n",
    "                if nc_count % 3 == 0:\n",
    "                    labels_list.append(0)\n",
    "                    features_list.append(img_gray)\n",
    "                nc_count += 1\n",
    "            else:\n",
    "                if c_count % 2 == 0:\n",
    "                    labels_list.append(1)\n",
    "                    features_list.append(img_gray)\n",
    "                c_count += 1\n",
    "                \n",
    "            \n",
    "\n",
    "with open(outfile_name, 'wb') as f:\n",
    "    pickle.dump([features_list, labels_list], f)\n",
    "                                        \n",
    "                        # clip = os.listdir('DataSet/'+ttv+'/'+user+'/'+extract+'/')[0]\n",
    "                        # print (clip[:-4])\n",
    "                        # path = os.path.abspath('.')+'/DataSet/'+ttv+'/'+user+'/'+extract+'/'\n",
    "                        # split_video(clip, clip[:-4], path)\n",
    "        # print(ttv, count)\n",
    "# print (\"================================================================================\\n\")\n",
    "# print (\"Frame Extraction Successful\")"
   ],
   "id": "4d6c26a12c6a3a53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [8:32:08<00:00, 1707.15s/it]  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "65a23314bdada669"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "67ab22d5acc383b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45ea750dbcc6ad9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea533ea27141af9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22196db257813781"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T04:11:21.367960Z",
     "start_time": "2024-05-31T04:11:21.307155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2 lists  to store the following\n",
    "# list of features (images)\n",
    "#{0: [[3, 1, 2, 2][4, 3, 2, 2]]}\n",
    "# list of labels (confused or not)\n",
    "#{0: 3}\n",
    "\n",
    "\n",
    "# loop over the train and test and validation\n",
    "for ttv in dataset:\n",
    "    # print(ttv, os.path.exists('DataSet/'+ttv+'/'))\n",
    "    \n",
    "    if ttv != '.DS_Store' and os.path.exists('../DAiSEE/DataSet/'+ttv+'/'):\n",
    "        # train, test, validation\n",
    "        count = 0\n",
    "        features_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        users = os.listdir('../DAiSEE/DataSet/'+ttv+'/')\n",
    "        # print(users)\n",
    "        if ttv == 'Test':\n",
    "            all_clips = test_csv[['ClipID', 'Confusion']]\n",
    "            outfile_name = 'Test.pkl'\n",
    "            # print(all_clips)\n",
    "        if ttv == 'Train':\n",
    "            all_clips = train_csv[['ClipID', 'Confusion']]\n",
    "            outfile_name = 'Train.pkl'\n",
    "        if ttv == 'Validation':\n",
    "            all_clips = valid_csv[['ClipID', 'Confusion']]\n",
    "            outfile_name = 'Validation.pkl'\n",
    "            \n",
    "        for user in tqdm(users):\n",
    "            if user != '.DS_Store':\n",
    "                # user is the folder, has 300 jpeg\n",
    "                # extract jpeg\n",
    "                currUser = os.listdir('../DAiSEE/DataSet/'+ttv+'/'+user+'/')\n",
    "                \n",
    "                # extract is still a folder (10s clip each folder)\n",
    "                for extract in currUser:\n",
    "                    \n",
    "                    if extract != '.DS_Store':\n",
    "                        content_list = os.listdir('../DAiSEE/DataSet/'+ttv+'/'+user+'/'+extract+'/')\n",
    "                                        \n",
    "                        if pd.Series(content_list).isin(all_clips['ClipID']).any():\n",
    "                            confusion_val = all_clips.loc[all_clips['ClipID'].isin(content_list)].Confusion.to_list()[0]\n",
    "                            # remove video for below\n",
    "                            img_list = [c for c in content_list if c.endswith('.jpg')]\n",
    "                            sort_nicely(img_list)\n",
    "                            # if confusion_val == 0 or 1, skip every 30 (1s)\n",
    "                            # elif confusion_val == 2 or 3, skip every 3 (0.1s)\n",
    "                            if confusion_val == 0: #6000\n",
    "                                chosen = img_list[149] \n",
    "                            elif confusion_val == 1: #2200 * 1 = 2200\n",
    "                                chosen = img_list[149] \n",
    "                            elif confusion_val == 2: # 750 * 11 = 8250\n",
    "                                chosen = img_list[::27]\n",
    "                            elif confusion_val == 3: # 101 * 80 = 8080\n",
    "                                chosen = img_list[::4]\n",
    "                            # chosen  = random.choice(img_list)\n",
    "                            for item in img_list: \n",
    "                                \n",
    "                                if item in chosen:\n",
    "                                    count += 1\n",
    "                                    img_path = os.path.abspath('.')+'/../DAiSEE/DataSet/'+ttv+'/'+user+'/'+extract+'/'+item\n",
    "                                    img = cv2.imread(str(img_path))\n",
    "                                    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                                    img_gray = cv2.resize(img_gray, (128, 128))\n",
    "                                    \n",
    "                                    # img is 3d array (w, h, 1), label is confusion_val\n",
    "                                    features_list.append(img_gray)\n",
    "                                    # if confusion_val is 0 or 1, then = 0\n",
    "                                    if confusion_val == 0 or confusion_val == 1:\n",
    "                                        labels_list.append(0)\n",
    "                                    # # elif confusion_val is 2 or 3, then = 1 and 2\n",
    "                                    elif confusion_val == 2 or confusion_val == 3:\n",
    "                                        labels_list.append(confusion_val-1)\n",
    "                                    # labels_list.append(confusion_val)\n",
    "        \n",
    "        with open(outfile_name, 'wb') as f:\n",
    "            pickle.dump([features_list, labels_list], f)\n",
    "                                        \n",
    "                        # clip = os.listdir('DataSet/'+ttv+'/'+user+'/'+extract+'/')[0]\n",
    "                        # print (clip[:-4])\n",
    "                        # path = os.path.abspath('.')+'/DataSet/'+ttv+'/'+user+'/'+extract+'/'\n",
    "                        # split_video(clip, clip[:-4], path)\n",
    "        # print(ttv, count)\n",
    "# print (\"================================================================================\\n\")\n",
    "# print (\"Frame Extraction Successful\")"
   ],
   "id": "687b11f09deb167a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:40:55.501524Z",
     "start_time": "2024-05-20T00:40:55.498260Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "15d430c0574ef615",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:40:55.524891Z",
     "start_time": "2024-05-20T00:40:55.504167Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7307651b9ba5dd4f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:40:55.549119Z",
     "start_time": "2024-05-20T00:40:55.542128Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "470dc22ee577ae4e",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
